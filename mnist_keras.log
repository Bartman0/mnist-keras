2025-06-29 23:27:17.618157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1751232437.628684   66023 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1751232437.632184   66023 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-06-29 23:27:17.643722: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1751232439.791758   66023 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7792 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:54:00.0, compute capability: 8.6
X_train: (60000, 28, 28)
Y_train: (60000,)
X_test:  (10000, 28, 28)
Y_test:  (10000,)
-------- MNIST 0 as ASCII --------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@*:-=#%@@@@@@@@@@@@@@@@
@@@@@@.     ::::::::-#@@@@@@
@@@@@@#+#+-. .    .  =@@@@@@
@@@@@@@@@@@@#@####@  +@@@@@@
@@@@@@@@@@@@@@@@@@* .@@@@@@@
@@@@@@@@@@@@@@@@@@  *@@@@@@@
@@@@@@@@@@@@@@@@@=  %@@@@@@@
@@@@@@@@@@@@@@@@#  #@@@@@@@@
@@@@@@@@@@@@@@@@= :@@@@@@@@@
@@@@@@@@@@@@@@@@. #@@@@@@@@@
@@@@@@@@@@@@@@@+ :@@@@@@@@@@
@@@@@@@@@@@@@@#  #@@@@@@@@@@
@@@@@@@@@@@@@@. -@@@@@@@@@@@
@@@@@@@@@@@@@: .%@@@@@@@@@@@
@@@@@@@@@@@@%  *@@@@@@@@@@@@
@@@@@@@@@@@%. +@@@@@@@@@@@@@
@@@@@@@@@@@=  #@@@@@@@@@@@@@
@@@@@@@@@@#   #@@@@@@@@@@@@@
@@@@@@@@@@+  .%@@@@@@@@@@@@@
@@@@@@@@@@+ .@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
----------------------------------
-------- MNIST 1 as ASCII --------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@++-  =*@@@@@@@@@@@
@@@@@@@@@-      .%@@@@@@@@@@
@@@@@@@@-   .=-  +@@@@@@@@@@
@@@@@@@#  .%@@@. =@@@@@@@@@@
@@@@@@@* .%@@@+  #@@@@@@@@@@
@@@@@@@@%@@@@@.  #@@@@@@@@@@
@@@@@@@@@@@@@+  :@@@@@@@@@@@
@@@@@@@@@@@@*   #@@@@@@@@@@@
@@@@@@@@@@@@=  =@@@@@@@@@@@@
@@@@@@@@@@@-  -@@@@@@@@@@@@@
@@@@@@@@@@%   %@@@@@@@@@@@@@
@@@@@@@@@@:  =@@@@@@@@@@@@@@
@@@@@@@@@*  :@@@@@@@@@@@@@@@
@@@@@@@@@:  =@@@@@@@@@@@@@@@
@@@@@@@@=  -@@@@@@@@@@@@@@@@
@@@@@@@@   %@@@@@@@@@@@@@@@@
@@@@@@@@   %@@@@@@@@@%====@@
@@@@@@@@        -=-       +@
@@@@@@@@-              -++#@
@@@@@@@@@++++-   -++%@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
----------------------------------
-------- MNIST 2 as ASCII --------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@% +@@@@@@@@@
@@@@@@@@@@@@@@@@* *@@@@@@@@@
@@@@@@@@@@@@@@@@= @@@@@@@@@@
@@@@@@@@@@@@@@@% =@@@@@@@@@@
@@@@@@@@@@@@@@@* #@@@@@@@@@@
@@@@@@@@@@@@@@@:.@@@@@@@@@@@
@@@@@@@@@@@@@@% .@@@@@@@@@@@
@@@@@@@@@@@@@@* :@@@@@@@@@@@
@@@@@@@@@@@@@@= *@@@@@@@@@@@
@@@@@@@@@@@@@# .@@@@@@@@@@@@
@@@@@@@@@@@@@+ -@@@@@@@@@@@@
@@@@@@@@@@@@@- *@@@@@@@@@@@@
@@@@@@@@@@@@@ .@@@@@@@@@@@@@
@@@@@@@@@@@@+ -@@@@@@@@@@@@@
@@@@@@@@@@@@= =@@@@@@@@@@@@@
@@@@@@@@@@@@. #@@@@@@@@@@@@@
@@@@@@@@@@@#  #@@@@@@@@@@@@@
@@@@@@@@@@@= .@@@@@@@@@@@@@@
@@@@@@@@@@@. +@@@@@@@@@@@@@@
@@@@@@@@@@@:-@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
----------------------------------
-------- MNIST 3 as ASCII --------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@= :%@@@@@@@@@@@
@@@@@@@@@@@@%   +@@@@@@@@@@@
@@@@@@@@@@@@:   +@@@@@@@@@@@
@@@@@@@@@@+:    -+#@@@@@@@@@
@@@@@@@@@@        .#@@@@@@@@
@@@@@@@@@:      .   @@@@@@@@
@@@@@@@@#.    =*#=  +@@@@@@@
@@@@@@@%    .=@@@%   +@@@@@@
@@@@@@@%   :@@@@@@+   %@@@@@
@@@@@@@%  :%@@@@@@%:  %@@@@@
@@@@@@@%  @@@@@@@@%:  -@@@@@
@@@@@@@=  @@@@@@@@+   %@@@@@
@@@@@@@.  @@@@@@@#    %@@@@@
@@@@@@@.  @@@@@@=   .#@@@@@@
@@@@@@@.  @@@@@:.   :@@@@@@@
@@@@@@@.  ##.       @@@@@@@@
@@@@@@@+           =@@@@@@@@
@@@@@@@%         :%@@@@@@@@@
@@@@@@@@#=      +@@@@@@@@@@@
@@@@@@@@@@#- -##%@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
----------------------------------
-------- MNIST 4 as ASCII --------
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@%.@@@@@@@#%@@@@@@@
@@@@@@@@@@+ @@@@@@@=-@@@@@@@
@@@@@@@@@@: @@@@@@@*.@@@@@@@
@@@@@@@@@# =@@@@@@@+ @@@@@@@
@@@@@@@@% .@@@@@@@@: @@@@@@@
@@@@@@@@- #@@@@@@@@  @@@@@@@
@@@@@@@* .@@@@@@@@= :@@@@@@@
@@@@@@@- +@@@@@@@%  #@@@@@@@
@@@@@@@. @@@@@@@@= .@@@@@@@@
@@@@@@@ -@@@@@@@@- -@@@@@@@@
@@@@@@@..@@@@@@@@  +@@@@@@@@
@@@@@@@- :****=-:  +@@@@@@@@
@@@@@@@%-          @@@@@@@@@
@@@@@@@@@%****@@-  @@@@@@@@@
@@@@@@@@@@@@@@@@+  %@@@@@@@@
@@@@@@@@@@@@@@@@=  @@@@@@@@@
@@@@@@@@@@@@@@@@+  @@@@@@@@@
@@@@@@@@@@@@@@@@=  @@@@@@@@@
@@@@@@@@@@@@@@@@  +@@@@@@@@@
@@@@@@@@@@@@@@@@:#@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
@@@@@@@@@@@@@@@@@@@@@@@@@@@@
----------------------------------
x_train shape: (60000, 28, 28, 1)
60000 train samples
10000 test samples
Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                 │ (None, 26, 26, 32)     │           320 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 13, 13, 32)     │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_1 (Conv2D)               │ (None, 11, 11, 64)     │        18,496 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 5, 5, 64)       │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten (Flatten)               │ (None, 1600)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 1600)           │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 10)             │        16,010 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 34,826 (136.04 KB)
 Trainable params: 34,826 (136.04 KB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/10
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1751232441.236447   66095 service.cc:148] XLA service 0x7fccbc003c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1751232441.236476   66095 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6
2025-06-29 23:27:21.252933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1751232441.317318   66095 cuda_dnn.cc:529] Loaded cuDNN version 90300
I0000 00:00:1751232442.669797   66095 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2025-06-29 23:27:23.617095: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_705', 8 bytes spill stores, 8 bytes spill loads

2025-06-29 23:27:23.689629: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_705', 12 bytes spill stores, 12 bytes spill loads

422/422 - 5s - 11ms/step - accuracy: 0.8920 - loss: 0.3544 - val_accuracy: 0.9792 - val_loss: 0.0780
Epoch 2/10
422/422 - 1s - 2ms/step - accuracy: 0.9660 - loss: 0.1111 - val_accuracy: 0.9838 - val_loss: 0.0563
Epoch 3/10
422/422 - 1s - 2ms/step - accuracy: 0.9739 - loss: 0.0842 - val_accuracy: 0.9857 - val_loss: 0.0492
Epoch 4/10
422/422 - 1s - 2ms/step - accuracy: 0.9776 - loss: 0.0712 - val_accuracy: 0.9870 - val_loss: 0.0451
Epoch 5/10
422/422 - 1s - 2ms/step - accuracy: 0.9804 - loss: 0.0619 - val_accuracy: 0.9887 - val_loss: 0.0402
Epoch 6/10
422/422 - 1s - 2ms/step - accuracy: 0.9825 - loss: 0.0558 - val_accuracy: 0.9907 - val_loss: 0.0392
Epoch 7/10
422/422 - 1s - 2ms/step - accuracy: 0.9837 - loss: 0.0525 - val_accuracy: 0.9913 - val_loss: 0.0339
Epoch 8/10
422/422 - 1s - 2ms/step - accuracy: 0.9852 - loss: 0.0477 - val_accuracy: 0.9907 - val_loss: 0.0325
Epoch 9/10
422/422 - 1s - 2ms/step - accuracy: 0.9869 - loss: 0.0427 - val_accuracy: 0.9912 - val_loss: 0.0325
Epoch 10/10
422/422 - 1s - 2ms/step - accuracy: 0.9871 - loss: 0.0404 - val_accuracy: 0.9893 - val_loss: 0.0336
Test loss: 0.028370672836899757
Test accuracy: 0.9890000224113464
image 0 is considered to be: 7
image 1 is considered to be: 2
image 2 is considered to be: 1
image 3 is considered to be: 0
image 4 is considered to be: 4
